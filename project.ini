# General project settings
[PROJECT]
# REQUIRED
PROJECT_NAME = crowl
# REQUIRED
START_URL = https://www.yenibiris.com/

# Crawler settings
[CRAWLER]

USER_AGENT = Crowl (+https://www.yenibiris.com/)
# Obey robots.txt ? Default: True.
ROBOTS_TXT_OBEY = True
# Exclusion pattern: URLs matching this regex will be ignored.
EXCLUSION_PATTERN = 
# Time to wait between requests (in seconds). Default: 0.5.
DOWNLOAD_DELAY = 0.5
# Number of crawler threads. Default: 5.
CONCURRENT_REQUESTS = 5
# Default: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
MIME_TYPES = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
# Default: en
ACCEPT_LANGUAGE = en

# Data extraction settings
[EXTRACTION]
# Store links ? Default: False.
LINKS = False
# Store page content ? Default: False.
CONTENT = False
# Maximum crawl depth. Default: 5.
DEPTH = 5


[OUTPUT]
crowl.CrowlCsvPipeline = 100
#crowl.CrowlMySQLPipeline = 200

# MySQL settings if you use MySQL as output
[MYSQL]
MYSQL_HOST = localhost
MYSQL_PORT = 3306
MYSQL_USER = 
MYSQL_PASSWORD = 

